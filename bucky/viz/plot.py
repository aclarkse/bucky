"""Creates line plots with confidence intervals at the ADM0, ADM1, or ADM2 level."""
import argparse
import glob
import logging
import os
import sys

import matplotlib
import matplotlib.pyplot as plt
import pandas as pd
import tqdm

from ..util.get_historical_data import get_historical_data
from ..util.read_config import bucky_cfg
from ..util.readable_col_names import readable_col_names
from .geoid import read_geoid_from_graph, read_lookup

# from matplotlib.ticker import StrMethodFormatter  # isort:skip

# Disable weird y-axis formatting
matplotlib.rc("axes.formatter", useoffset=False)

plt.style.use("ggplot")

parser = argparse.ArgumentParser(description="Bucky model plotting tools")

# Location of processed data
parser.add_argument(
    "-i",
    "--input_dir",
    default=max(
        glob.glob(os.path.join(bucky_cfg["output_dir"], "*/")),
        key=os.path.getctime,
        default="Most recently created folder in output_dir",
    ),
    type=str,
    help="Directory location of aggregated data",
)

# Output directory
parser.add_argument(
    "-o",
    "--output",
    default=None,
    type=str,
    help="Output directory for plots. Defaults to input_dir/plots/",
)

# Graph file used for this run. Defaults to most recently created
parser.add_argument(
    "-g",
    "--graph_file",
    default=None,
    type=str,
    help="Graph file used during model. Defaults to most recently created graph",
)

# Aggregation levels, e.g. state, county, etc.
parser.add_argument(
    "-l",
    "--levels",
    default=["adm0", "adm1"],
    nargs="+",
    type=str,
    help="Requested plot levels",
)

# Columns for plot, historical data
default_plot_cols = ["daily_reported_cases", "daily_deaths"]

parser.add_argument(
    "--plot_columns",
    default=default_plot_cols,
    nargs="+",
    type=str,
    help="Columns to plot",
)

# Can pass in a lookup table to use in place of graph
parser.add_argument(
    "--lookup",
    default=None,
    type=str,
    help="Lookup table for geographic mapping info",
)

# Pass in the minimum number of historical data points to plot
parser.add_argument("--min_hist", default=0, type=int, help="Minimum number of historical data points to plot.")

# Pass in a specific historical start date and historical file
parser.add_argument(
    "--hist_start",
    default=None,
    type=str,
    help="Start date of historical data. If not passed in, will align with start date of simulation",
)

# Optional flags
parser.add_argument(
    "--adm1_name",
    default=None,
    type=str,
    help="Admin1 to make admin2-level plots for",
)

parser.add_argument(
    "--end_date",
    default=None,
    type=str,
    help="Data will not be plotted past this point",
)

parser.add_argument("-v", "--verbose", action="store_true", help="Print extra information")

parser.add_argument(
    "-hist",
    "--hist",
    action="store_true",
    help="Plot historical data in addition to simulation data",
)

parser.add_argument(
    "--hist_file",
    type=str,
    default=None,
    help="Path to historical data file. If None, uses either CSSE or \
            Covid Tracking data depending on columns requested.",
)

parser.add_argument(
    "-q",
    "--quantiles",
    nargs="+",
    type=float,
    default=None,
    help="Specify the quantiles to plot. Defaults to all quantiles present in data.",
)

# Size of window in days
parser.add_argument(
    "-w",
    "--window_size",
    default=7,
    type=int,
    help="Size of window (in days) to apply to historical data",
)


def plot(
    out_dir,
    lookup_df,
    key,
    sim_data,
    hist_data,
    plot_columns,
    quantiles,
):
    """Given a dataframe and a key, creates plots with requested columns.

    For example, a pandas.DataFrame with state-level data would create a plot for
    each unique state. Simulation data is plotted as a line with shaded
    confidence intervals. Historical data is added as scatter points if
    requested.

    Parameters
    ----------
    out_dir : str
        Location to place created plots.
    lookup_df : pandas.DataFrame
        Dataframe containing information relating different geographic
        areas
    key : str
        Key to use to relate simulation data and geographic areas. Must
        appear in lookup and simulation data (and historical data if
        applicable)
    sim_data : pandas.DataFrame
        Simulation data to plot
    hist_data : pandas.DataFrame
        Historical data to add to plot
    plot_columns : list of str
        Columns to plot
    quantiles : list of float, or None
        List of quantiles to plot. If None, will plot all available
        quantiles in data.
    """
    # If quantiles were not specified, get all quantiles present in data
    if quantiles is None:
        quantiles = sim_data["quantile"].unique()

    # Get number of quantiles
    num_intervals = len(quantiles)

    # make sure they're sorted
    quantiles.sort()

    # Drop lookup nans
    lookup_df = lookup_df.dropna()

    # Make one plot for each area
    # For state plots, one plot per state
    # For counties, one plot per county
    unique_sim_areas = sim_data[key].unique()
    unique_lookup_areas = lookup_df[key].unique()

    # Some lookups have a subset. Use whichever set of areas is smaller
    if len(unique_sim_areas) < len(unique_lookup_areas):
        unique_areas = unique_sim_areas
    else:
        unique_areas = unique_lookup_areas

    for area in tqdm.tqdm(unique_areas, total=len(unique_areas), desc="Plotting " + key, dynamic_ncols=True):

        # Get name
        name = lookup_df.loc[lookup_df[key] == area][key + "_name"].values[0]

        # If admin2-level, get admin1-level as well
        # TODO change to function call with descriptive name
        if key == "adm2":

            admin1_name = lookup_df.loc[lookup_df[key] == area]["adm1_name"].values[0]
            name = admin1_name + " : " + name

        # Get data for this area
        area_data = sim_data.loc[sim_data[key] == area]
        area_data = area_data.assign(date=pd.to_datetime(area_data["date"]))

        # Initialize figure
        fig, axs = plt.subplots(
            2,
            sharex=True,
            gridspec_kw={"hspace": 0.1, "height_ratios": [2, 1]},
            figsize=(15, 7),
        )
        fig.suptitle(name.upper())

        for i, col in enumerate(plot_columns):

            # Set index
            area_data = area_data.set_index(["date", "quantile"])

            # Middle is median
            median_data = area_data.xs(quantiles[int(num_intervals / 2)], level=1)[col]
            dates = median_data.index.values

            # Plot median and outer quantiles
            median_data.plot(
                linewidth=1.5,
                color="k",
                alpha=0.75,
                label=readable_col_names[col],
                ax=axs[i],
            )

            # Iterate over pairs of quantiles
            num_quantiles = len(quantiles)

            # Scale opacity
            alpha = 1.0 / (num_quantiles // 2)
            for q in range(num_quantiles // 2):

                lower_q = quantiles[q]
                upper_q = quantiles[num_quantiles - 1 - q]

                lower_data = area_data.xs(lower_q, level=1)[col]
                upper_data = area_data.xs(upper_q, level=1)[col]

                axs[i].fill_between(
                    dates,
                    lower_data,
                    upper_data,
                    linewidth=0,
                    alpha=alpha,
                    color="b",
                    interpolate=True,
                )

            # axs[i].set_ylim([.8*oq_lower.min(), 1.2*oq_upper.max()])
            area_data = area_data.reset_index()

            # Plot historical data which is already at the correct level
            if hist_data is not None and i <= (len(plot_columns) - 1):

                actuals = hist_data.loc[hist_data[key] == area]
                if not actuals.empty and plot_columns[i] in hist_data.columns:

                    actuals = actuals.assign(date=pd.to_datetime(actuals["date"]))
                    # actuals.set_index('date', inplace=True)
                    hist_label = "Historical " + readable_col_names[plot_columns[i]]
                    actuals.plot(x="date", y=plot_columns[i], ax=axs[i], color="r", marker="o", ls="", label=hist_label)

                    # Set xlim
                    axs[i].set_xlim(actuals["date"].min(), dates.max())
                    # axs[i].scatter(actual_dates[ind:], actual_vals[ind:], label='Historical data', color='b')
                else:
                    logging.warning("Historical data missing for area: " + name + ", column=" + plot_columns[i])

            axs[i].grid(True)
            axs[i].legend()
            axs[i].set_ylabel("Count")
            # axs[i].yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))

        plot_filename = os.path.join(out_dir, readable_col_names[plot_columns[0]] + "_" + name + ".png")
        plot_filename = plot_filename.replace(" : ", "_")
        plot_filename = plot_filename.replace(" ", "")
        plt.savefig(plot_filename)
        plt.close()

        # Save CSV
        csv_filename = os.path.join(out_dir, name + ".csv")
        area_data.to_csv(csv_filename)


def make_plots(
    adm_levels,
    input_directory,
    output_directory,
    lookup_df,
    plot_hist,
    plot_columns,
    quantiles,
    window_size,
    end_date,
    hist_file,
    min_hist_points,
    admin1=None,
    hist_start=None,
):
    """Wrapper function around plot. Creates plots, aggregating data if necessary.

    Parameters
    ----------
    adm_levels : list of str
        List of ADM levels to make plots for
    input_directory : str
        Location of simulation data
    output_directory : str
        Parent directory to place created plots.
    lookup : pandas.DataFrame
        Lookup table for geographic mapping information
    plot_hist : bool
        If True, will plot historical data.
    plot_columns : list of str
        List of columns to plot from data.
    quantiles : list of float, or None
        List of quantiles to plot. If None, will plot all available
        quantiles in data.
    window_size : int
        Size of window (in days) to apply to historical data.
    end_date : str
        Plot data until this date. Must be formatted as YYYY-MM-DD.
        If None, uses last date in simulation.
    hist_file : string
        Path to historical data file. If None, uses either CSSE or
        Covid Tracking data depending on columns requested.
    min_hist_points : int
        Minimum number of historical data points to plot.
    admin1 : list of str, or None
        List of admin1 values to make plots for. If None, a plot will be
        created for every unique admin1 values. Otherwise, plots are
        only made for those requested.
    hist_start : str
        Plot historical data from this point (formatted as YYYY-MM-DD).
        If None, aligns with simulation start date.
    """
    # Loop over requested levels
    for level in adm_levels:

        filename = level + "_quantiles.csv"

        # Read the requested file from the input dir
        data = pd.read_csv(os.path.join(input_directory, filename))
        data = data.assign(date=pd.to_datetime(data["date"]))

        # Get dates for data
        start_date = data["date"].min()
        if end_date is not None:
            end_date = pd.to_datetime(end_date)
        else:
            end_date = data["date"].max()

        # Drop data not within range
        data = data.loc[(data["date"] < end_date) & (data["date"] > start_date)]

        # Determine if sub-folder is necessary (state or county-level)
        plot_dir = output_directory
        if level in ["adm2", "adm1"]:

            plot_dir = os.path.join(plot_dir, level.upper())

            # create directory
            if not os.path.exists(plot_dir):
                os.makedirs(plot_dir)

        # For admin2 only: if a admin1 name was passed in, only keep data within that admin1
        if level == "adm2" and admin1 is not None:

            admin2_vals = lookup_df.loc[lookup_df["adm1_name"] == admin1]["adm2"].unique()
            data = data.loc[data["adm2"].isin(admin2_vals)]

        # Read historical data if needed
        hist_data = None
        if plot_hist:

            # Get historical data for requested columns
            hist_data = get_historical_data(plot_columns, level, lookup_df, window_size, hist_file)

            # Check if historical data was not successfully fetched
            if hist_data is None:
                logging.warning("No historical data could be found for: " + str(plot_columns))

            else:
                hist_data = hist_data.reset_index()

                # Drop data not within requested time range
                hist_data = hist_data.assign(date=pd.to_datetime(hist_data["date"]))

                if hist_start is not None:
                    start_date = hist_start

                # Check that there are the minimum number of points
                last_hist_date = hist_data["date"].max()
                num_points = (last_hist_date - pd.to_datetime(start_date)).days

                # Shift start date if necessary
                if num_points < min_hist_points:
                    start_date = last_hist_date - pd.Timedelta(str(min_hist_points) + " days")

                hist_data = hist_data.loc[(hist_data["date"] < end_date) & (hist_data["date"] > start_date)]
        plot(
            out_dir=plot_dir,
            lookup_df=lookup_df,
            key=level,
            sim_data=data,
            hist_data=hist_data,
            plot_columns=plot_columns,
            quantiles=quantiles,
        )


if __name__ == "__main__":

    # Logging
    logging.basicConfig(
        level=logging.WARNING,
        stream=sys.stdout,
        format="%(asctime)s - %(levelname)s - %(filename)s:%(funcName)s:%(lineno)d - %(message)s",
    )

    # Parse CLI args
    args = parser.parse_args()
    logging.info(args)

    # Parse arguments
    input_dir = args.input_dir

    output_dir = args.output

    if output_dir is None:
        output_dir = os.path.join(input_dir, "plots")

    # Make sure output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # aggregation levels
    levels = args.levels

    # Columns for plotting
    plot_cols = args.plot_columns

    if args.lookup is not None:
        lookup_table = read_lookup(args.lookup)
    else:
        lookup_table = read_geoid_from_graph(args.graph_file)

    # Historical data start
    hist_start_date = args.hist_start

    # Parse optional flags
    window = args.window_size
    plot_historical = args.hist
    verbose = args.verbose
    plot_end_date = args.end_date
    list_quantiles = args.quantiles
    hist_data_file = args.hist_file
    min_hist = args.min_hist

    # If a historical file was passed in, make sure hist is also true
    if hist_data_file is not None:
        plot_historical = True

    # Plot
    make_plots(
        levels,
        input_dir,
        output_dir,
        lookup_table,
        plot_historical,
        plot_cols,
        list_quantiles,
        window,
        plot_end_date,
        hist_data_file,
        min_hist,
        args.adm1_name,
        hist_start_date,
    )
